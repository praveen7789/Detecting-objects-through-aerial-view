{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I have a about 200 images in the below folder 'train' glob will get all the images from folder here\n",
    "path = glob.glob('./train/*.JPG')\n",
    "image=[]\n",
    "for img in path:\n",
    "    v = cv.imread(img) #It will loads all the images from a file\n",
    "    blur = cv.GaussianBlur(v,(5,5),0)\n",
    "    gray = cv.cvtColor(blur,cv.COLOR_BGR2GRAY)# here changing  color image to gray scale\n",
    "    image.append(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=os.listdir('train')#it will get on the images names from a directory\n",
    "string = ''.join(names)\n",
    "result=re.findall(r'\\_(\\d)',string)\n",
    "Birds = list(map(int, result))\n",
    "len(Birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for certain features:\n",
    "def Headers(Kernel):\n",
    "    x,y = np.nonzero(thresh)  #It will returns the nonzero values of the array\n",
    "    x = x - np.mean(x)\n",
    "    y = y - np.mean(y)\n",
    "    coords = np.vstack([x, y])\n",
    "    vax = [np.var(x)]          #Variance(x)\n",
    "    vax = np.nan_to_num(vax)   # It will replace any null values with zeros\n",
    "    vay = [np.var(y)]          #Variance(y)\n",
    "    vay = np.nan_to_num(vay)\n",
    "    correlation = [np.corrcoef(x,y)[0][1]] #correlation\n",
    "    correlation = np.nan_to_num(correlation)\n",
    "    covariance = [np.cov(x,y)[0][1]]    #covariance\n",
    "    covariance = np.nan_to_num(covariance)\n",
    "    cov = np.cov(coords)\n",
    "    cov= np.nan_to_num(cov)\n",
    "    evals, evecs = np.linalg.eig(cov) #creating eigen values and eigen vectors\n",
    "    sort_indices =np.argsort(evals)[::-1] # index sorting & inversing [::-1]\n",
    "    x_v1,y_v1 = evecs[:, sort_indices[0]]  # Eigenvector with largest eigenvalue\n",
    "    x_v2,y_v2 = evecs[:, sort_indices[1]]  # Eigenvector with lowest eigenvalue\n",
    "    \n",
    "    angel1 = math.degrees(np.arctan(y_v1/x_v1))   #theta value of 1st vector\n",
    "    angel2= math.degrees(np.arctan(y_v2/x_v2))    #theta value of 2nd vector\n",
    "    return  vax,vay,correlation,covariance,angel1,angel2 #It will give us all above defined values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3157: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:356: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:78: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:2392: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:2326: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:2326: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  del sys.path[0]\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:2400: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:2401: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# we are going to extract all features for all images \n",
    "for i in image:    \n",
    "    #Here we are using different kernels/Filters to extract features needed form all the images\n",
    " \n",
    "    \n",
    "    #blur = cv.GaussianBlur(i,(5,5),cv.CV_64F)\n",
    "    fil = cv.bilateralFilter(i,5,cv.CV_32F,150,150)\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3))\n",
    "    ero = cv.erode(fil,kernel,iterations=2)\n",
    "    laplacian = cv.Laplacian(ero,cv.CV_64F)\n",
    "    _,thresh = cv.threshold(laplacian,15,255,cv.THRESH_BINARY)\n",
    "    vaxL,vayL,ccL,dataL,angelL1,angelL2 = Headers(laplacian) #applying function with new variables names\n",
    "\n",
    "    \n",
    "    #blur = cv.GaussianBlur(i,(5,5),cv.CV_64F)\n",
    "    cann = cv.Canny(i,cv.CV_8U,100,200)\n",
    "    _,thresh = cv.threshold(cann,15,255,cv.THRESH_BINARY)\n",
    "    vaxC,vayC,ccC,dataC,angelC1,angelC2 = Headers(cann) #applying function  with new variables names\n",
    "     \n",
    "    #blur = cv.GaussianBlur(i,(5,5),cv.CV_64F)\n",
    "    scharrx = cv.Scharr(fil,cv.CV_64F,1,0)# scharrx \n",
    "    scharry = cv.Scharr(fil,cv.CV_64F,0,1) #scharry\n",
    "    scharr = cv.addWeighted(scharrx,0.5,scharry,0.5,0)\n",
    "    scharr_ = np.maximum(scharr,50) # threshold the value to 50\n",
    "    scharr_[scharr_==50]=0 # collect those values\n",
    "    _, thresh = cv.threshold(scharr_,15,255,cv.THRESH_BINARY)#create a thershold\n",
    "    vaxS,vayS,ccS,dataS,angelS1,angelS2 = Headers(scharr_)#applying function to kernel4 with new variables names\n",
    "\n",
    "    #blur = cv.GaussianBlur(i,(5,5),cv.CV_64F)\n",
    "    sobelx = cv.Sobel(i,cv.CV_64F,1,0,ksize=5) # sobel x\n",
    "    sobely = cv.Sobel(i,cv.CV_64F,0,1,ksize=5) # sobel y\n",
    "    sobel = cv.addWeighted(sobelx,0.5,sobely,0.5,0) # sobel = sobel x + sobel y\n",
    "    sobel_ = np.maximum(sobel,50) # threshold the value to 50\n",
    "    sobel_[sobel_==50]=0 # collect those values\n",
    "    _, thresh = cv.threshold(sobel_,15,255,cv.THRESH_BINARY)#create a thershold\n",
    "    vaxO,vayO,ccO,dataO,angelO1,angelO2 = Headers(sobel_) #applying function to kernel1 with new variables namesthose values\n",
    "    \n",
    "    \n",
    "    \n",
    "    # This gives a matrix with same dimesions of our image with all values being 75\n",
    "    matrix = np.ones(i.shape, dtype = \"uint8\") * 75\n",
    "    # We use the matrix to add to our image\n",
    "    added = cv2.add(i, matrix)\n",
    "    _,thresh = cv.threshold(added,15,255,cv.THRESH_BINARY)\n",
    "    vaxa,vaya,cca,dataa,angela1,angela2 = Headers(added)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                                  [-1, 9,-1],\n",
    "                                  [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(i, -1, kernel_sharpening)\n",
    "    _,thresh = cv.threshold(added,15,255,cv.THRESH_BINARY)\n",
    "    vaxsh,vaysh,ccsh,datash,angelsh1,angelsh2 = Headers(added)\n",
    "    \n",
    "   \n",
    "    #Creating a data frame table for all the features obtained for each kernel:\n",
    "    \n",
    "    data={'vaxO':vaxO,'vayO':vayO,'ccO':ccO,'dataO':dataO,'angelO1':angelO1,'angelO2':angelO2,'vaxL':vaxL,'vayL':vayL,'ccL':ccL,'dataL':dataL,'angelL1':angelL1,'angelL2':angelL2,'vaxS':vaxS,'vayS':vayS,'ccS':ccS,'dataS':dataS,'angelS1':angelS1,'angelS2':angelS2,\n",
    "    'vaxC':vaxC,'vayC':vayC,'ccC':ccC,'dataC':dataC,'angelC1':angelC1,'angelC2':angelC2,'vaxa':vaxa,'vaya':vaya,'cca':cca,'dataa':dataa,'angela1':angela1,'angela2':angela2,\n",
    "         'vaxsh':vaxsh,'vaysh':vaysh,'ccsh':ccsh,'datash':datash,'angelsh1':angelsh1,'angelsh2':angelsh2}\n",
    "        \n",
    "\n",
    "    df_temp = pd.DataFrame(data=data)\n",
    "    try:\n",
    "         df = pd.concat((df,df_temp),ignore_index=True)\n",
    "    except:\n",
    "        df = df_temp\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# It is always a good habit to \\nimport cv2\\nimport numpy as np\\n# Reading in the input image\\nfor i in image:\\n    #image = cv2.imread(\\'images/input.jpg\\')\\n    # Create a matrix of ones of type int in the same size as the image\\n    # then multiply it by a scaler of 75 \\n    # This gives a matrix with same dimesions of our image with all values being 75\\n    matrix = np.ones(i.shape, dtype = \"uint8\") * 75\\n    # We use the matrix to add to our image\\n    added = cv2.add(i, matrix)\\n    cv2.imshow(\"Added\", added)\\n    # Likewise we can also subtract\\n    subtracted = cv2.subtract(i, matrix)\\n    cv2.imshow(\"Subtracted\", subtracted)\\n    # Wait & terminate\\n    cv2.waitKey(0)\\n    cv2.destroyAllWindows()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# It is always a good habit to \n",
    "import cv2\n",
    "import numpy as np\n",
    "# Reading in the input image\n",
    "for i in image:\n",
    "    #image = cv2.imread('images/input.jpg')\n",
    "    # Create a matrix of ones of type int in the same size as the image\n",
    "    # then multiply it by a scaler of 75 \n",
    "    # This gives a matrix with same dimesions of our image with all values being 75\n",
    "    matrix = np.ones(i.shape, dtype = \"uint8\") * 75\n",
    "    # We use the matrix to add to our image\n",
    "    added = cv2.add(i, matrix)\n",
    "    cv2.imshow(\"Added\", added)\n",
    "    # Likewise we can also subtract\n",
    "    subtracted = cv2.subtract(i, matrix)\n",
    "    cv2.imshow(\"Subtracted\", subtracted)\n",
    "    # Wait & terminate\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# It is always a good habit to \\nimport cv2\\nimport numpy as np\\n# Reading in the input image\\nfor i in image:\\n    #image = cv2.imread(\\'images/input.jpg\\')\\n    # Create a matrix of ones of type int in the same size as the image\\n    # then multiply it by a scaler of 75 \\n    # This gives a matrix with same dimesions of our image with all values being 75\\n    matrix = np.ones(i.shape, dtype = \"uint8\") * 75\\n    # We use the matrix to add to our image\\n    added = cv2.add(i, matrix)\\n    _,thresh = cv.threshold(added,15,255,cv.THRESH_BINARY)\\n    vaxa,vaya,cca,dataa,angelSa,angelSa = Headers(added)\\n    \\n    \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# It is always a good habit to \n",
    "import cv2\n",
    "import numpy as np\n",
    "# Reading in the input image\n",
    "for i in image:\n",
    "    #image = cv2.imread('images/input.jpg')\n",
    "    # Create a matrix of ones of type int in the same size as the image\n",
    "    # then multiply it by a scaler of 75 \n",
    "    # This gives a matrix with same dimesions of our image with all values being 75\n",
    "    matrix = np.ones(i.shape, dtype = \"uint8\") * 75\n",
    "    # We use the matrix to add to our image\n",
    "    added = cv2.add(i, matrix)\n",
    "    _,thresh = cv.threshold(added,15,255,cv.THRESH_BINARY)\n",
    "    vaxa,vaya,cca,dataa,angelSa,angelSa = Headers(added)\n",
    "    \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in image:\\n    kernel_sharpening = np.array([[-1,-1,-1], \\n                                  [-1, 9,-1],\\n                                  [-1,-1,-1]])\\n    sharpened = cv2.filter2D(i, -1, kernel_sharpening)\\n    _,thresh = cv.threshold(added,15,255,cv.THRESH_BINARY)\\n    vaxsh,vaysh,ccsh,datash,angelSsh,angelSsh = Headers(added)\\n    '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in image:\n",
    "    kernel_sharpening = np.array([[-1,-1,-1], \n",
    "                                  [-1, 9,-1],\n",
    "                                  [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(i, -1, kernel_sharpening)\n",
    "    _,thresh = cv.threshold(added,15,255,cv.THRESH_BINARY)\n",
    "    vaxsh,vaysh,ccsh,datash,angelSsh,angelSsh = Headers(added)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4181.25])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaxsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bird=np.array(Birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 36)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bird']=Bird "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Birda_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaxO</th>\n",
       "      <th>vayO</th>\n",
       "      <th>ccO</th>\n",
       "      <th>dataO</th>\n",
       "      <th>angelO1</th>\n",
       "      <th>angelO2</th>\n",
       "      <th>vaxL</th>\n",
       "      <th>vayL</th>\n",
       "      <th>ccL</th>\n",
       "      <th>dataL</th>\n",
       "      <th>...</th>\n",
       "      <th>dataa</th>\n",
       "      <th>angela1</th>\n",
       "      <th>angela2</th>\n",
       "      <th>vaxsh</th>\n",
       "      <th>vaysh</th>\n",
       "      <th>ccsh</th>\n",
       "      <th>datash</th>\n",
       "      <th>angelsh1</th>\n",
       "      <th>angelsh2</th>\n",
       "      <th>Bird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3675.948992</td>\n",
       "      <td>3719.873990</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>80.923200</td>\n",
       "      <td>52.592989</td>\n",
       "      <td>-37.407011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3965.735177</td>\n",
       "      <td>3218.404725</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>-206.246065</td>\n",
       "      <td>-14.445753</td>\n",
       "      <td>75.554247</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3886.114991</td>\n",
       "      <td>3889.515733</td>\n",
       "      <td>-0.009079</td>\n",
       "      <td>-35.302245</td>\n",
       "      <td>-46.378941</td>\n",
       "      <td>43.621059</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4244.191365</td>\n",
       "      <td>4221.542235</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>33.737701</td>\n",
       "      <td>35.721709</td>\n",
       "      <td>-54.278291</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4027.260821</td>\n",
       "      <td>4398.653690</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>74.666737</td>\n",
       "      <td>79.057519</td>\n",
       "      <td>-10.942481</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          vaxO         vayO       ccO       dataO    angelO1    angelO2  vaxL  \\\n",
       "0  3675.948992  3719.873990  0.021881   80.923200  52.592989 -37.407011  0.00   \n",
       "1  3965.735177  3218.404725 -0.057718 -206.246065 -14.445753  75.554247  0.25   \n",
       "2  3886.114991  3889.515733 -0.009079  -35.302245 -46.378941  43.621059  0.00   \n",
       "3  4244.191365  4221.542235  0.007970   33.737701  35.721709 -54.278291  0.00   \n",
       "4  4027.260821  4398.653690  0.017723   74.666737  79.057519 -10.942481  0.00   \n",
       "\n",
       "   vayL  ccL  dataL  ...   dataa  angela1  angela2    vaxsh    vaysh  ccsh  \\\n",
       "0   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "1   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "2   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "3   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "4   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "\n",
       "   datash  angelsh1  angelsh2  Bird  \n",
       "0     0.0      90.0       0.0     1  \n",
       "1     0.0      90.0       0.0     1  \n",
       "2     0.0      90.0       0.0     0  \n",
       "3     0.0      90.0       0.0     0  \n",
       "4     0.0      90.0       0.0     0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "data = pd.read_csv('./Birda_data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0',axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaxO</th>\n",
       "      <th>vayO</th>\n",
       "      <th>ccO</th>\n",
       "      <th>dataO</th>\n",
       "      <th>angelO1</th>\n",
       "      <th>angelO2</th>\n",
       "      <th>vaxL</th>\n",
       "      <th>vayL</th>\n",
       "      <th>ccL</th>\n",
       "      <th>dataL</th>\n",
       "      <th>...</th>\n",
       "      <th>dataa</th>\n",
       "      <th>angela1</th>\n",
       "      <th>angela2</th>\n",
       "      <th>vaxsh</th>\n",
       "      <th>vaysh</th>\n",
       "      <th>ccsh</th>\n",
       "      <th>datash</th>\n",
       "      <th>angelsh1</th>\n",
       "      <th>angelsh2</th>\n",
       "      <th>Bird</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3675.948992</td>\n",
       "      <td>3719.873990</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>80.923200</td>\n",
       "      <td>52.592989</td>\n",
       "      <td>-37.407011</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3965.735177</td>\n",
       "      <td>3218.404725</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>-206.246065</td>\n",
       "      <td>-14.445753</td>\n",
       "      <td>75.554247</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3886.114991</td>\n",
       "      <td>3889.515733</td>\n",
       "      <td>-0.009079</td>\n",
       "      <td>-35.302245</td>\n",
       "      <td>-46.378941</td>\n",
       "      <td>43.621059</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4244.191365</td>\n",
       "      <td>4221.542235</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>33.737701</td>\n",
       "      <td>35.721709</td>\n",
       "      <td>-54.278291</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4027.260821</td>\n",
       "      <td>4398.653690</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>74.666737</td>\n",
       "      <td>79.057519</td>\n",
       "      <td>-10.942481</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>4181.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          vaxO         vayO       ccO       dataO    angelO1    angelO2  vaxL  \\\n",
       "0  3675.948992  3719.873990  0.021881   80.923200  52.592989 -37.407011  0.00   \n",
       "1  3965.735177  3218.404725 -0.057718 -206.246065 -14.445753  75.554247  0.25   \n",
       "2  3886.114991  3889.515733 -0.009079  -35.302245 -46.378941  43.621059  0.00   \n",
       "3  4244.191365  4221.542235  0.007970   33.737701  35.721709 -54.278291  0.00   \n",
       "4  4027.260821  4398.653690  0.017723   74.666737  79.057519 -10.942481  0.00   \n",
       "\n",
       "   vayL  ccL  dataL  ...   dataa  angela1  angela2    vaxsh    vaysh  ccsh  \\\n",
       "0   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "1   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "2   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "3   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "4   0.0  0.0    0.0  ...     0.0     90.0      0.0  4181.25  4181.25   0.0   \n",
       "\n",
       "   datash  angelsh1  angelsh2  Bird  \n",
       "0     0.0      90.0       0.0     1  \n",
       "1     0.0      90.0       0.0     1  \n",
       "2     0.0      90.0       0.0     0  \n",
       "3     0.0      90.0       0.0     0  \n",
       "4     0.0      90.0       0.0     0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb00d737d30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Bird'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('Bird',axis=1)\n",
    "y = data['Bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "x = minmax_scale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  7],\n",
       "       [ 1, 19]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_hat,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "  n_features_to_select=None, step=1, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "selector = RFE(model)   #applying RFE to logistic regression\n",
    "selector.fit(x_train,y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  6,  1,  1,  1,  1,  1,  3,  1,  1,  1,  1,  1,\n",
       "        2,  7,  4,  1,  5,  1,  1,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.ranking_#ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('Bird',axis=1)\n",
    "y = data['Bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vaxO</th>\n",
       "      <th>vayO</th>\n",
       "      <th>ccO</th>\n",
       "      <th>dataO</th>\n",
       "      <th>angelO1</th>\n",
       "      <th>vaxL</th>\n",
       "      <th>vayL</th>\n",
       "      <th>ccL</th>\n",
       "      <th>dataL</th>\n",
       "      <th>angelL1</th>\n",
       "      <th>vaxS</th>\n",
       "      <th>vayS</th>\n",
       "      <th>ccS</th>\n",
       "      <th>dataS</th>\n",
       "      <th>angelS1</th>\n",
       "      <th>ccC</th>\n",
       "      <th>angelC1</th>\n",
       "      <th>angelC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3675.948992</td>\n",
       "      <td>3719.873990</td>\n",
       "      <td>0.021881</td>\n",
       "      <td>80.923200</td>\n",
       "      <td>52.592989</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>347.238668</td>\n",
       "      <td>373.335094</td>\n",
       "      <td>0.153292</td>\n",
       "      <td>55.325192</td>\n",
       "      <td>51.650580</td>\n",
       "      <td>0.793427</td>\n",
       "      <td>33.046472</td>\n",
       "      <td>-56.953528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3965.735177</td>\n",
       "      <td>3218.404725</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>-206.246065</td>\n",
       "      <td>-14.445753</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1394.961069</td>\n",
       "      <td>568.740974</td>\n",
       "      <td>-0.251580</td>\n",
       "      <td>-224.481457</td>\n",
       "      <td>-14.238525</td>\n",
       "      <td>-0.130505</td>\n",
       "      <td>-7.679449</td>\n",
       "      <td>82.320551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3886.114991</td>\n",
       "      <td>3889.515733</td>\n",
       "      <td>-0.009079</td>\n",
       "      <td>-35.302245</td>\n",
       "      <td>-46.378941</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3105.286818</td>\n",
       "      <td>1796.707429</td>\n",
       "      <td>-0.728930</td>\n",
       "      <td>-1744.130536</td>\n",
       "      <td>-34.596355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4244.191365</td>\n",
       "      <td>4221.542235</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>33.737701</td>\n",
       "      <td>35.721709</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4501.795657</td>\n",
       "      <td>5587.706746</td>\n",
       "      <td>0.054039</td>\n",
       "      <td>273.610422</td>\n",
       "      <td>76.736415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4027.260821</td>\n",
       "      <td>4398.653690</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>74.666737</td>\n",
       "      <td>79.057519</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vaxO         vayO       ccO       dataO    angelO1  vaxL  vayL  ccL  \\\n",
       "0  3675.948992  3719.873990  0.021881   80.923200  52.592989  0.00   0.0  0.0   \n",
       "1  3965.735177  3218.404725 -0.057718 -206.246065 -14.445753  0.25   0.0  0.0   \n",
       "2  3886.114991  3889.515733 -0.009079  -35.302245 -46.378941  0.00   0.0  0.0   \n",
       "3  4244.191365  4221.542235  0.007970   33.737701  35.721709  0.00   0.0  0.0   \n",
       "4  4027.260821  4398.653690  0.017723   74.666737  79.057519  0.00   0.0  0.0   \n",
       "\n",
       "   dataL  angelL1         vaxS         vayS       ccS        dataS    angelS1  \\\n",
       "0    0.0     90.0   347.238668   373.335094  0.153292    55.325192  51.650580   \n",
       "1    0.0      0.0  1394.961069   568.740974 -0.251580  -224.481457 -14.238525   \n",
       "2    0.0     90.0  3105.286818  1796.707429 -0.728930 -1744.130536 -34.596355   \n",
       "3    0.0     90.0  4501.795657  5587.706746  0.054039   273.610422  76.736415   \n",
       "4    0.0     90.0     0.000000     0.000000  0.000000     0.000000  90.000000   \n",
       "\n",
       "        ccC    angelC1    angelC2  \n",
       "0  0.793427  33.046472 -56.953528  \n",
       "1 -0.130505  -7.679449  82.320551  \n",
       "2  0.000000  90.000000   0.000000  \n",
       "3  0.000000  90.000000   0.000000  \n",
       "4  0.000000  90.000000   0.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BirdClass1= x[x.columns[selector.support_]]#it will create a df with all obtained features\n",
    "BirdClass1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(minmax_scale(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "degreeoffreedom = 140-1-(21-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                   Bird   No. Observations:                  160\n",
      "Model:                            GLM   Df Residuals:                      136\n",
      "Model Family:                Binomial   Df Model:                           23\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -71.560\n",
      "Date:                Sun, 14 Apr 2019   Deviance:                       143.12\n",
      "Time:                        22:32:46   Pearson chi2:                     245.\n",
      "No. Iterations:                     6   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "0              1.5266      2.415      0.632      0.527      -3.207       6.260\n",
      "1             -3.1334      2.498     -1.254      0.210      -8.029       1.762\n",
      "2             56.0120     31.404      1.784      0.074      -5.538     117.562\n",
      "3            -46.9020     27.827     -1.686      0.092    -101.441       7.637\n",
      "4             -0.2140      1.061     -0.202      0.840      -2.294       1.866\n",
      "5              0.7625      0.913      0.835      0.404      -1.028       2.553\n",
      "6             -0.3502      1.851     -0.189      0.850      -3.979       3.278\n",
      "7              1.7198      1.838      0.936      0.350      -1.883       5.323\n",
      "8              2.0265      1.899      1.067      0.286      -1.696       5.749\n",
      "9              4.0814      3.241      1.259      0.208      -2.270      10.433\n",
      "10            -1.7193      1.334     -1.289      0.198      -4.334       0.896\n",
      "11            -1.1450      1.507     -0.760      0.447      -4.098       1.808\n",
      "12            -1.4112      1.586     -0.890      0.373      -4.519       1.697\n",
      "13            -1.6902      1.219     -1.387      0.165      -4.079       0.698\n",
      "14             0.2748      1.835      0.150      0.881      -3.321       3.871\n",
      "15             2.2497      3.264      0.689      0.491      -4.148       8.647\n",
      "16            -1.5708      1.008     -1.558      0.119      -3.547       0.406\n",
      "17             0.6264      1.148      0.546      0.585      -1.623       2.876\n",
      "18            -1.4737      1.543     -0.955      0.340      -4.499       1.551\n",
      "19             1.3322      2.517      0.529      0.597      -3.601       6.265\n",
      "20             5.9134      2.374      2.491      0.013       1.261      10.566\n",
      "21            -5.5499      3.940     -1.409      0.159     -13.272       2.172\n",
      "22            -5.2263      1.115     -4.688      0.000      -7.411      -3.041\n",
      "23             1.1923      1.281      0.931      0.352      -1.318       3.703\n",
      "24                  0          0        nan        nan           0           0\n",
      "25                  0          0        nan        nan           0           0\n",
      "26                  0          0        nan        nan           0           0\n",
      "27                  0          0        nan        nan           0           0\n",
      "28                  0          0        nan        nan           0           0\n",
      "29                  0          0        nan        nan           0           0\n",
      "30                  0          0        nan        nan           0           0\n",
      "31                  0          0        nan        nan           0           0\n",
      "32                  0          0        nan        nan           0           0\n",
      "33                  0          0        nan        nan           0           0\n",
      "34                  0          0        nan        nan           0           0\n",
      "35                  0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "INFO: Null deviance = 221.70708735991082\n",
      "INFO: Residual deviance = 143.11906366707547\n",
      "INFO: Critical Value of chi2 = 145.46074022476483\n",
      "INFO: Pearson chi2 = 244.76911197284727\n",
      "INFO: P-value chi2 = 1.0043221809752367e-10\n",
      "INFO: AIC = 191.11906366707547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/praveen/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "#Creating a new Logistic model for our new data\n",
    "model = sm.GLM(y_train,x_train,family=sm.families.Binomial()).fit()#logistic belongs to binomial family i;e normal distribution\n",
    "print(model.summary())\n",
    "#we have calculate below values to know our model perform.\n",
    "print('INFO: Null deviance =',model.null_deviance)\n",
    "print('INFO: Residual deviance =',model.deviance)\n",
    "print('INFO: Critical Value of chi2 =',chi2.ppf(0.95,degreeoffreedom))\n",
    "print('INFO: Pearson chi2 =',model.pearson_chi2)\n",
    "print('INFO: P-value chi2 =',1-chi2.cdf(model.pearson_chi2,degreeoffreedom))\n",
    "print('INFO: AIC =',model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will replaces the probability values with 0's and 1's\n",
    "def probreplace(y):#Here y is the function variable is called when ever required\n",
    "    if y >= 0.52:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives the predicted probability values for train and test data and storing in new variables\n",
    "y_train_prob = model.predict(x_train)\n",
    "y_test_prob = model.predict(x_test)\n",
    "#Applying the above function to replace prob values and storing in new variables\n",
    "y_pred_train= y_train_prob.apply(probreplace)\n",
    "y_pred_test = y_test_prob.apply(probreplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A  ConfusionMatrix is a table that is often used to describe the performance of a  model\n",
    "from pandas_ml import ConfusionMatrix   \n",
    "cm_train = ConfusionMatrix(y_train,y_pred_train)\n",
    "cm_test = ConfusionMatrix(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Confusion Matrix for Traning Data \n",
      "\n",
      " Predicted  False  True  __all__\n",
      "Actual                         \n",
      "False         66    12       78\n",
      "True          17    65       82\n",
      "__all__       83    77      160 \n",
      "\n",
      "\n",
      "INFO: Confusion Matrix for Testing Data \n",
      "\n",
      " Predicted  False  True  __all__\n",
      "Actual                         \n",
      "False         19     3       22\n",
      "True           5    13       18\n",
      "__all__       24    16       40\n"
     ]
    }
   ],
   "source": [
    "print('INFO: Confusion Matrix for Traning Data \\n\\n',cm_train,'\\n\\n')\n",
    "print('INFO: Confusion Matrix for Testing Data \\n\\n',cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Traning Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Accuracy', 0.81875),\n",
       "             ('95% CI', (0.7501802648267919, 0.8751260075850857)),\n",
       "             ('No Information Rate', 'ToDo'),\n",
       "             ('P-Value [Acc > NIR]', 2.3062596443798096e-15),\n",
       "             ('Kappa', 0.6378395254448954),\n",
       "             (\"Mcnemar's Test P-Value\", 'ToDo')])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('For Traning Data')#gives overall performance of a model\n",
    "cm_train.stats_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Testing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Accuracy', 0.8),\n",
       "             ('95% CI', (0.6435219813207653, 0.9094775906000093)),\n",
       "             ('No Information Rate', 'ToDo'),\n",
       "             ('P-Value [Acc > NIR]', 0.00606462839872809),\n",
       "             ('Kappa', 0.5918367346938777),\n",
       "             (\"Mcnemar's Test P-Value\", 'ToDo')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('For Testing Data')\n",
    "cm_test.stats_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model dump and model loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189    0.777780\n",
       "44     0.636528\n",
       "150    0.955465\n",
       "183    0.994182\n",
       "113    0.306203\n",
       "169    0.135467\n",
       "116    0.930397\n",
       "156    0.468769\n",
       "32     0.933816\n",
       "136    0.836466\n",
       "10     0.233309\n",
       "161    0.483451\n",
       "112    0.110479\n",
       "2      0.170568\n",
       "124    0.253500\n",
       "68     0.464133\n",
       "138    0.070880\n",
       "38     0.995679\n",
       "153    0.435292\n",
       "33     0.951707\n",
       "70     0.458543\n",
       "127    0.853994\n",
       "1      0.940563\n",
       "154    0.178826\n",
       "89     0.619137\n",
       "39     0.320628\n",
       "92     0.471459\n",
       "56     0.091443\n",
       "85     0.195349\n",
       "19     0.129603\n",
       "197    0.357030\n",
       "73     0.542686\n",
       "98     0.183552\n",
       "76     0.185677\n",
       "109    0.928821\n",
       "58     0.489210\n",
       "71     0.207353\n",
       "180    0.955031\n",
       "173    0.565944\n",
       "80     0.088188\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "  \n",
    "# Save the trained model as a pickle string. \n",
    "saved_model = pickle.dumps(model) \n",
    "  \n",
    "# Load the pickled model \n",
    "glm_from_pickle = pickle.loads(saved_model) \n",
    "  \n",
    "# Use the loaded pickled model to make predictions \n",
    "glm_from_pickle.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Computes Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores.\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "fpr,tpr,threshold = roc_curve(y_train,y_train_prob)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(fpr,tpr,color='red',lw=1.5)\n",
    "plt.plot([0, 1], [0, 1], color='navy',lw = 2, linestyle='--')\n",
    "\n",
    "for i,value in enumerate(fpr*10):\n",
    "    try:\n",
    "        if (round(fpr[i+1]*10) - round(fpr[i]*10)) == 1:\n",
    "            plt.text(fpr[i],tpr[i],'%0.2f'%(threshold[i]))\n",
    "    except IndexError:\n",
    "        print(' ')\n",
    "        \n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(['ROC curve (area = %0.2f)' % auc(fpr,tpr)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "drugTree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTree = drugTree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_dt = ConfusionMatrix(y_train,drugTree.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/pandas_ml/confusion_matrix/stats.py:60: FutureWarning: supplying multiple axes to axis is deprecated and will be removed in a future version.\n",
      "  num = df[df > 1].dropna(axis=[0, 1], thresh=1).applymap(lambda n: choose(n, 2)).sum().sum() - np.float64(nis2 * njs2) / n2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Accuracy', 0.49606299212598426),\n",
       "             ('95% CI', (0.40617544957454527, 0.5861382890972416)),\n",
       "             ('No Information Rate', 'ToDo'),\n",
       "             ('P-Value [Acc > NIR]', 0.8764264269138978),\n",
       "             ('Kappa', -0.007187112763320896),\n",
       "             (\"Mcnemar's Test P-Value\", 'ToDo')])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_dt.stats_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAndom forest by this method we are able to get 90 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praveen/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8095238095238094"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "rmf=RandomForestClassifier(max_depth=3,random_state=42)\n",
    "rf_class=rmf.fit(x_train,y_train) # fiting model \n",
    "seed=7\n",
    "num_trees=30 # no of branches : 30 default\n",
    "kfold=model_selection.KFold(n_splits=14,random_state=seed) \n",
    "result=model_selection.cross_val_score(rf_class,x_train,y_train,cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8095238095238094"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=7\n",
    "num_trees=30 # no of branches : 30 default\n",
    "kfold=model_selection.KFold(n_splits=14,random_state=seed) \n",
    "result=model_selection.cross_val_score(rf_class,x_train,y_train,cv=kfold)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64 14]\n",
      " [ 5 77]] \n",
      "\n",
      " [[16  6]\n",
      " [ 1 17]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "rf_y_test=rf_class.predict(x_test)\n",
    "rf_y_train = rf_class.predict(x_train)\n",
    "rf_cm_test=confusion_matrix(y_test,rf_y_test)\n",
    "rf_cm_train = confusion_matrix(y_train,rf_y_train)\n",
    "print(rf_cm_train ,'\\n\\n', rf_cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of train =  0.88125 \n",
      " ======================================== \n",
      " accuracy of test =  0.825\n"
     ]
    }
   ],
   "source": [
    "rf_acc_train=accuracy_score(y_train,rf_y_train)\n",
    "rf_acc_test= accuracy_score(y_test,rf_y_test)\n",
    "print('accuracy of train = ',rf_acc_train , '\\n','='*40,'\\n' , 'accuracy of test = ',rf_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import KNeighborsClassifier model \n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN \n",
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNN(n_neighbors = 5) \n",
    "  \n",
    "# training model \n",
    "knn.fit(x_train, y_train) \n",
    "#accuracy test\n",
    "knn_acc_test= accuracy_score(y_train,y_hat_train)\n",
    "knn_acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving model through joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib \n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(knn, 'filename.pkl') \n",
    "  \n",
    "# Load the model from the file \n",
    "knn_from_joblib = joblib.load('filename.pkl')  \n",
    "  \n",
    "# Use the loaded model to make predictions \n",
    "knn_from_joblib.predict(x_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = knn_from_joblib.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted  False  True  __all__\n",
       "Actual                         \n",
       "False         31    33       64\n",
       "True          36    27       63\n",
       "__all__       67    60      127"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(y_train,y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "knn_acc_test= accuracy_score(y_train,y_hat_train)\n",
    "knn_acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecting K value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.725, 0.625, 0.8  , 0.7  , 0.775, 0.675, 0.725, 0.725, 0.7  ]),\n",
       " array([0.07060011, 0.07654655, 0.06324555, 0.07245688, 0.06602556,\n",
       "        0.07405657, 0.07060011, 0.07060011, 0.07245688]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "Ks = 10\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "std_acc = np.zeros((Ks-1))\n",
    "ConfustionMx = [];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(x_train,y_train)\n",
    "    yhat=neigh.predict(x_test)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n",
    "\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "mean_acc , std_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
